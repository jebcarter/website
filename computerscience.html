<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-H2HPCJKNTQ"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-H2HPCJKNTQ');
    </script>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.1/jquery.min.js"></script>
    <script src="myscripts.js"></script>

    <meta charset="utf-8">
    <title>Jeb Carter - Computer Science</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico">

  </head>
  <body>
    <div class="code-image">
      <div class="pagetitle">
        <h1 class="bubbletext">C O M P U T E R&nbsp; &nbsp;S C I E N C E</h1>
      </div>
    </div>
    <div class="sticky">
      <button onclick="document.location = 'index.html'" class="buttonpagelinks"
      style="vertical-align:middle"><span>Home </span></button>
      <button onclick="document.location = 'engineering.html'" class="buttonpagelinks"
      style="vertical-align:middle"><span>Engineering </span></button>
      <button onclick="document.location = 'computerscience.html'" class="buttonpagelinks"
      style="vertical-align:middle"><span>Computer Science </span></button>
      <button onclick="document.location = 'music.html'" class="buttonpagelinks"
      style="vertical-align:middle"><span>Music  </span></button>
    </div>
    <div class="special">
      <h2>Experience</h2>
      <p class="bodytext">
        During my time in college and graduate school, I built a strong programming foundation in
        Python, Java, and C, working on numerous start-to-finish projects in these languages.
        Some of these projects included implementing a full Unix Shell, implementing heap manager
        modules for system memory management, implementing Burrows-Wheeler data compression,
        writing code in assembly language, and developing Microsoft Powerapps, just to name a few. I've worked on
        several projects using 3D-Modeling software and I am
        also very comfortable working with HTML, CSS, RStudio, MATLAB, Wolfram Mathematica,
        Microsoft Office, and Photoshop.
        <br>
      </p>
      <p class="bodytext">
        Below, I have highlighted some of my more notable/interesting computer science projects to date. Note that
        this page only contains projects which are solely computer-focused. Projects with a hardware component
        are listed on the Engineering page, though many of them include a significant computing component as well.
        Those detailed on this page include:
        <ul>
          <li><a href="#RockPaperScissors">Rock-Paper-Scissors Battle</a></li>
          <li><a href="#KnightTrap">The Multiple Knight Trapping Problem</a></li>
          <li><a href="#KnightTour">The Knight's Tour</a></li>
          <li><a href="#8Puzzle">The Slider Puzzle Solver</a></li>
          <li><a href="#Recursive">Recursive Artwork</a></li>
          <li><a href="#NBody">The N-Body Problem</a></li>
          <li><a href="#Balls">Bouncing Balls</a></li>
        </ul>
      </p>
    </div>

<!---------------------------------------------------------------------------->
<!--                          Rock Paper Scissors                            ->
<!---------------------------------------------------------------------------->


<div class="main1">
  <h3 id="RockPaperScissors">Rock-Paper-Scissors Battle</h3>
  <h5>Background</h5>
  <p class="bodytext">
    This project is an exploration of a fun twist on a classic children's game: Rock-Paper-Scissors.
    The idea of a simulated multi-player rock-paper-scissors battle is not an original idea, but I
    enjoyed thinking about the idea when I first saw it online and was inspired to build it
    myself with my own personal implementations, features, and twists.
  </p>
  <h5>The Original Game</h5>
  <p class="bodytext">
    The basic idea of the game is a simple two-dimensional arena which contains a set of N players. Each player is initialized
    to one of three types: Rock, Paper, or Scissors. The players move around the screen and, as they collide, convert
    "target" players to their type (for example, scissors converts paper) according to traditional rock-paper-scissors rules.
    The primary decision relevant to the design of the game is choosing the heuristics that the players use to decide which
    direction to move. A rather naive heuristic would be for each player to simply move in the direction of their
    nearest target. (e.g. Rock moves toward the nearest scissors) This strategy has a number of issues: First of all, players
    will often run directly into their "foe" in an attempt to get to their target. Additionally, this heuristic allows players
    of the same type to bunch up and occupy the same space as they hunt toward the nearest shared target. Ideally, players
    of the same type should space themselves out a bit in order to avoid stacking on top of each other. Avoiding stacking makes
    for a better-looking game and also has the strategic advantage of preventing a "chain reaction" conversion.
  </p>
  <figure class="rightsmall">
    <img src="/images-videos/RPSLK/Heuristics.jpg" width="100%" height="215"
    alt="Player Heuristics Diagram">
    <figcaption>Player Heuristics Diagram</figcaption>
  </figure>
  <p class="bodytext">
    <b>My Default Heuristic:</b>
    The heuristic that I settled on for the first iteration of the game involves factors from all three player types.
    The chosen step direction of a player at a given epoch is calculated as the weighted sum of four unit vectors. The first
    vector, Aggression, points in the direction of the nearest target. The Cowardice vector points directly away
    from the nearest foe. The third vector, Personal Space, points away from the nearest player of the same type, or "friend".
    Finally, the fourth vector, Edge Penalty, points toward the center of the screen (away from the edges of the board). The Edge
    Penalty vector encourages the players not to huddle on the edges of the screen. These four vectors are weighted according to
    their relative emphasis in the heuristic and according to the distance from the player to its respective target, foe, friend,
    or wall. In other words, a vector is weighted more heavily if the corresponding target, foe, etc is closer to the original
    player.
  </p>
  <h5>The Rock-Paper-Scissors-Lizard-Spock Expansion</h5>
  <figure class="rightmedium">
    <img src="/images-videos/RPSLK/Game_Example.gif" width="100%" height="315"
    alt="5 Player Game Simulation">
    <figcaption>5 Player Game Simulation</figcaption>
  </figure>
  <p class="bodytext">
    Upon completing the base 3-player game, I became interested in the idea of an N-player game. With more than
    three player types, each would have more than one target and more than one foe, making the game much more
    interesting and increasing the customizability. One such game is a variation on rock-paper-scissors popularized by
    the TV Show "Big Bang Theory" called Rock-Paper-Scissors-Lizard-Spock. In this comedic variation, scissors cuts paper,
    paper cuts rock, rock crushes lizard, lizard poisons spock, spock smashes scissors, scissors decapitates lizard,
    lizard eats paper, paper disproves spock, spock vaporizes rock, and rock crushes scissors. Such a 5-way game results in
    two targets and two foes for each player and creates much more interesting game dynamics.
  </p>

  
  <h5>Leveraging Neural Networks to Model the Environment and Predict Outcomes</h5>
  <p class="bodytext">
    Once the game and corresponding GUI were completed, I implented statistics tools which can simulate large numbers of games for a
    given set of player heuristics, populating win percentages for all 5 players progressively. I subsequently exported this data
    to an external CSV and repeated this process for thousands of games, creating a large dataset representing the relative "fitness" of
    various players. The problem then became: <b>How can I predict the win rate of a player given the heuristics of all other players
    in the game?</b> Furthermore, <b>Can I generate an optimal player given a set of four opponents?</b> To answer these questions, I
    developed a pair of Neural Networks, Model 1 and Model 2, to accomplish each of these tasks.
  </p>
  <p class="bodytext">
    <b>Model 1 Methodology:</b> Model 1 is a Neural Network trained to predict the win percentage of a player given its behavior heuristics
    (aggression, cowardice, and personal space) and those of all other players. Since there are 5 players, each with 3 behavior
    characteristics, the network has 15 input nodes. It has a single output node which corresponds to the win rate of the first player
    (i.e., the player corresponding to the first 3 inputs of the NN). A general schematic of the network is shown below.
  </p>
  <figure class="middlewide">
    <img src="/images-videos/RPSLK/Model1.png" width="100%" height="470"
    alt="Model 1 - Neural Network Architecture">
    <figcaption>Model 1 - Neural Network Architecture</figcaption>
  </figure>
  <p class="bodytext">
    The win prediction model uses 3 hidden layers with 1000, 200, and 100 nodes each, respectively. The rationale behind this structure
    is rooted in the nature of the dataset. Specifically, the win rate of a player depends on more than the simple heuristics of all opponents
    with respect to player type 1. If the only interactions in the simulation were between player 1 and an opponent, a single hidden layer
    would likely be sufficient. However, the other players also interact with one another independently of player 1. As a consequence, the
    relative success or failure of player 1 depends not only on how its own heuristics interact with other players, but on how those players'
    heuristics interact with one another. For example, consider a scenario where player "Rock" has generally good heuristics
    (i.e., behaviors that would perform well in most simulations). Also consider that Rock's two targets, Scissors and Lizard, have very poor
    heuristic strategies (e.g., hyper-aggressive). In this environment, Scissors and Lizard are likely to go extinct early in the simulation,
    leaving Rock with only foes (in this case, Spock and Paper). Therefore, even though Rock had generally advisable heuristics, it may not
    perform well due to the interactions of other players around it. This is the motivation behind training a network with multiple hidden
    layers so that these subtle interdependencies may be captured.
  </p>
  <p class="bodytext">
    <b>Model 1 Results:</b> The model described above was trained and subsequently tested in Python using independent training and
    testing sets. The resulting model achieved an R<sup>2</sup> of 0.90. While a slightly higher R<sup>2</sup> would be desirable,
    this is an excellent metric. The simulations used to create the training and testing data are themselves subject to random variation,
    so the precision of the model is also subject to these perturbations away from the true win percentages. Each scenario was simulated
    N=100 times to minimize this effect, but it likely plays a significant role in lowering the upper ceiling on the optimality of the model.
    The figures below show the actual outputs in relation to the model's predicted outputs, as well as their residuals.
  </p>
  <figure class="middlewide">
    <img src="/images-videos/RPSLK/Model1_Output.png" width="100%" height="470"
    alt="Model 1 - Output vs Predictions and Output vs Residuals">
    <figcaption>Model 1 - Output vs Predictions and Output vs Residuals</figcaption>
  </figure>

  <p class="bodytext">
    <b>Model 2 Methodology - Brute Force Method:</b> Two different implementations of Model 2 were implemented for this project,
    each with its own benefits and drawbacks. The first implementation does not create a new model, but rather leverages the success of
    Model 1 to create a brute-force solution to emulate a player generation model. For any given player, there are 729 different possible
    combinations of the 3 heuristics (Personal Space, Cowardice, and Aggression, each ranging from 1 to 9). Because Model 1 is very reliable
    in predicting the win rate of a given player, one can simply iterate through all 729 different player configurations to determine which
    player has the highest win rate against a given set of opponents. The benefit of this model is that it is guaranteed to find the best
    possible player, as defined by Model 1. Unfortunately, it is also highly computationally intensive to calculate all 729 predictions,
    making this implementation impractical for any large-scale implementation.
  </p>
  <p class="bodytext">
    <b>Model 2 Methodology - Machine Learning Method:</b> The second implementation of Model 2 created in this project seeks to
    generate an optimal player using a neural network structure similar to Model 1. Unlike the first model, which attempts to determine the
    win probability, this model does not consider the specific win rate, but rather attempts to generate a new player which will achieve the
    highest-possible win rate against a particular set of opponents. A general schematic of the network is shown below.
  </p>
  <figure class="middlewide">
    <img src="/images-videos/RPSLK/Model2.png" width="100%" height="470"
    alt="Model 2 - Neural Network Architecture">
    <figcaption>Model 2 - Neural Network Architecture</figcaption>
  </figure>
  <p class="bodytext">
    This model has 12 input nodes, corresponding to the 3 heuristics of all 4 opponents, and 3 output nodes, corresponding to the 3
    heuristics of the newly generated player. The network structure chosen for this model has two hidden layers with 1000 and 200 nodes,
    respectively. The rationale behind this choice is similar to the rationale used for Model 1. Notably, this model should be expected to
    pick up on many of the same subtle interactions between players which can impact relative player fitness. Only 2 hidden layers were
    chosen for Model 2 (as opposed to 3 for Model 1) because the model proved susceptible to overfitting with too much complexity.
  </p>
  <p class="bodytext">
    The primary obstacle in creating a viable player generation model was the inaccessibility of high-quality training data.
    Specifically, the model needed to be trained using simulation outcomes where the optimal player is known. Using the simulation
    environment alone, it would be incredibly slow and computationally intensive to determine the optimal player for many sets of
    opponents, as that would require many rounds of simulation for each potential player just to generate a single datapoint. Instead,
    the model was trained using the output of Model 1, which can already reliably determine the win rate of a given player against a
    set of opponents. In order to generate data to train Model 2, optimal players were determined for random sets of opponents by exhaustive
    brute-force search, choosing fitness using the win rate prediction given by Model 1. This technique proved successful in creating large
    quantities of high-quality training data.
  </p>
  <p class="bodytext">
    <b>Model 2 Results:</b> Model 2 also achieved a positive outcome, but not according to the same statistical metrics which validate
    Model 1. Training Model 2 using the brute-force implementation described in the previous section yielded R<sup>2</sup> values of
    0.64, 0.69, and 0.67 for each of the three outputs, Personal Space, Cowardice, and Aggression, respectively. The figures below
    show the actual outputs in relation to the model's predicted outputs, as well as their residuals.
  </p>
  <figure class="middletall">
    <img src="/images-videos/RPSLK/Model2_Output.png" width="100%" height="620"
    alt="Model 2 - Output vs Predictions and Output vs Residuals">
    <figcaption>Model 2 - Output vs Predictions and Output vs Residuals</figcaption>
  </figure>
  <p class="bodytext">
    <b>Model 2 Results - A Deeper Dive:</b> At first glance, these results appear significantly inferior to the R<sup>2</sup> value generated by Model 1. However, closer
    consideration of the data reveals that Model 2 is actually highly successful. The primary consideration is that there are often
    several possible players with almost exactly the same win percentage. Consider a player with two candidate configurations for "optimality".
    The two best-possible heuristics are 3/6/4 and 1/8/2 with win percentages of 45% and 46%, respectively. Obviously, the training
    data would prefer the latter option as it achieves a higher win percentage. Let us assume, however, that Model 2 selects the former
    option due to random variation. In this situation, the neural network successfully achieved a nearly-optimal player but will be scored
    according to how close its chosen heuristics (3/6/4) align with the so-called "optimal" heuristics (1/8/2). This trend results in
    R<sup>2</sup> scoring that is considerably more pessimistic about the fitness of the model than its true performance.
  </p>
  <p class="bodytext">
    For a better measure of Model 2's performance, one can compare the win rate of the generated player to the win rate of the theoretically
    optimal player, as determined by Model 1. This strategy has the benefit of allowing Model 2 to find equally good alternatives by scoring
    on performance rather than precision. Performing this analysis on the model shows that the players generated by the neural network model
    have win rates that are less than 2% off each's respective optimal player win rate. Evaluating the win percentages of NN-generated
    players against the optimal win percentages yields an <b>R<sup>2</sup> value of 0.99.</b> This analysis illustrates that the player
    generation model has considerably higher performance than its initial analysis would suggest.
  </p>

  <h5>GUI Integration for Behavioral Controls, Modeling, and Simulation</h5>
  <p class="bodytext">
    The final addition to the project was a comprehensive GUI to allow the user to vary heuristic weights, create illustrations
    and visualization aids, simulate large numbers of game instances, and even leverage machine learning models to predict
    simulation outcomes. The full GUI is shown in the image below:
  </p>
  <figure class="middletall">
    <img src="/images-videos/RPSLK/GUI.png" width="100%" height="620"
    alt="Custom GUI">
    <figcaption>Custom GUI</figcaption>
  </figure>
  <p class="bodytext">
    The GUI has 6 major sections: Behavior Control, Statistics & Modeling Output, Environment Configuration,
    Statistics & Modeling Tools, Animation & Visualization Tools, and a Real-Time Data Logger.
    <br><br>
    <b>Section 1 - Behavior Control:</b> The top three rows of the GUI include slider bars to control the
    relative weights of the three behavior heuristics: personal space, cowardice, and aggression. These fields can be varied
    between 1-9, where larger numbers indicate a higher relative importance in calculating the resulting movement vector for
    players of that type. Notably, the resulting movement vector depends on the <em>relative</em> scale of each heuristic.
    This means that a 4-2-2 set of heuristics is actually the same as 8-4-4 because the relative scale between heuristics is equal. 
    <br><br>
    <b>Section 2 - Statistics & Modeling Output:</b> Below the player heuristic control section, there are two rows that display
    percentages. The top row (black font) contains the win percentages resulting from simulating a large number of hidden simulations using
    the heuristics and environment configuration currently specified. This field continuously updates as more simulations are completed.
    Below the simulation output, there is a second row (red font) with another set of percentages. This field contains the <em>predicted</em>
    win percentages of the 5 players, as specified by the Win Prediction Neural Network described above. Ideally, the win prediction
    field should closely match the simulation output, indicating a successful neural network prediction.
    <br><br>
    <b>Section 3 - Environment Configuration:</b> The next section contains a set of miscellaneous tools used to vary certain
    hyperparameters related to the simulation environment. The first two fields control, respectively, the number of players and the
    animation speed of the simulation. The other two fields reset all player heuristics to their default and randomize all player
    heuristics.
    <br><br>
    <b>Section 4 - Statistics & Modeling Tools:</b> These tools allow the user to simulate large numbers of games
    to determine outcome statistics. They also facilitate the use of machine learning models to predict simulation outcomes and
    generate new and strategic heuristic strategies. The "Predict Win Rates" button uses Model 1 (Predict Win Rates) to predict the
    simulation outcome of the current set of players. The two "Generate Rock" buttons use the Machine Learning and Brute Force methods,
    respectively, to generate a Rock player with optimal heuristics.
    <br><br>
    <b>Section 5 - Animation & Visualization Tools:</b> The next section has three buttons related to game animation and data
    visualization.
    <br><br>
    <b>Section 6 - Data Logger:</b> Finally, the bottom section of the GUI is a real-time information logger which prints the status
    of game simulations and provides positive feedback for buttons throughout the GUI.
  </p>

  <h5>Conclusion</h5>
  <p class="bodytext">
    This project constituted a fascinating exploration of many concepts involved in game theory, zero-sum game interactions,
    swarm decision making, and heuristic-based relative fitness. What began as a simple simulation-style game grew into a set of neural
    networks built on the foundations of thousands of datapoints. The first model was trained to predict the win rate of a player given its
    behavior heuristics and those of its opponents. From there, a second neural network designed to generate optimal players was created
    using training data generated by the first model. Ultimately, both models proved highly effective at achieving their respective goals
    and now persist as functional features of the Rock-Paper-Scissors-Lizard-Spock game simulation environment.
  </p>
</div>


<!---------------------------------------------------------------------------->
<!--                          Knight Trap                                    ->
<!---------------------------------------------------------------------------->

    <div class="main2">
      <h3 id="KnightTrap">The Multiple Knight Trapping Problem</h3>
      <figure class="rightlarge">
        <img src="/images-videos/Knight_Trap/Number_Label.jpg" width="100%" height="425"
        alt="Spiral Labeling">
        <figcaption>Spiral Labeling of Board</figcaption>
      </figure>
      <p class="bodytext">
        This project is inspired by
        <a href="https://www.youtube.com/channel/UCoxcjq-8xIDTYp3uz647V5A" title="Go to Numberphile Channel"
        target="_blank">Numberphile's</a>
        YouTube video entitled
        <a href="https://www.youtube.com/watch?v=RGQe8waGJ4w&t=62s" title="Go to Video"
        target="_blank">"The Trapped Knight"</a>.
      </p>
      <p class="bodytext">
        As far as I know, I am the first person to investigate this puzzle in the way and
        to the extent that I have and the first to produce the infinite sequence
        of integers resulting from it to the degree that I have.
        <b>The following puzzle, its solution, and the analysis of its results are entirely
        my own.</b> I call this problem The Multiple Knight Trapping Problem. The algorithm that
        I created to solve it computes a unique, infinite sequence of numbers given by
        the following problem:
      </p>
      <h5>Background</h5>
      <p class="bodytext">
        The Knight Trapping Problem is a fascinating problem involving the
        mechanics of a knight on a chess board. The problem presents the following scenario, a knight is
        placed on an infinitely large chess board. The squares on this board are labeled in
        a very particular way. As shown in the diagram (right), the center
        square is given the value (1), then the values increase in a spiral shape infinitely
        outward. Initially, the knight is placed at square (1).
      </p>
      <figure class="leftmedium">
        <img src="/images-videos/Knight_Trap/Knight_Trap-1.gif" width="100%" height="315"
        alt="First Trapping Square gif">
        <figcaption>Discovery of the First Trapping Square</figcaption>
      </figure>
      <p class="bodytext">
        The knight (moves like a knight from chess) begins at the central square (1)
        and can move to any legal square (making an "L" shape). For example, a
        knight at (1) could move to (10), (12), (14), (16), (18), (20), (22), or (24). The knight has
        two movement constraints: It cannot visit a square it has already been to,
        and it will always jump to the square with the smallest value. Once there,
        the knight will again compare the squares' values of all legal moves, with
        the exception of square (1), which it has already visited.
      </p>
      <p class="bodytext">
        This process continues until, at some point, the knight becomes 'trapped'.
        In this situation, the knight has already visited all 8 of the potential squares that
        it could legally jump to. A square where the knight becomes trapped is called
        a "trapping square." The first time the knight reaches one of these trapping squares
        is at square (2084). An animation of the knight discovering the first trapping square
        is shown (right). In the Numberphile video upon which this project is based,
        the problem stops there; since the knight is trapped, its path is over and 2084 is
        the magical number where that occurs.
      </p>
      <h5>My Algorithm</h5>
      <p class="bodytext">
        However, I was interested in whether or not the knight would get trapped <b>again</b>
        if it could continue moving beyond square (2084). This is where the problem becomes
        a creation of my own design and thus, my algorithm is born. Once the knight reaches any
        'trapping square,' it jumps backward a square to before it became trapped. (I made
        sure to keep a running cache of all recent moves for this purpose). From there, the
        knight continues past that trapping square until it gets trapped at a new one,
        at which point this process repeats.
        <br><br>
      </p>
      <figure class="videomedium">
        <video width="350" height="350" controls autoplay>
          <source src="/images-videos/Knight_Trap/Knight_Trap-8.mp4"
          type="video/mp4">
          Your browser does not support this video.
        </video>
        <figcaption>Discovery of the First 8 Trapping Squares</figcaption>
      </figure>
      <p class="bodytext">
        By exploring farther and farther out into the board, the algorithm produces a series of integers,
        which are the values associated with each trapping square that the knight discovers.
        I have run my knight trapping algorithm for the first 5,000,000 trapping squares.
        Doing so required allocating my entire computer's 16GB of RAM to the task
        simultaneously and allowing the program to run for several hours in
        addition to a number of other optimizations. Within the first 5,000,000, the
        farthest trapping square discovered has a staggering value of (13,224,016,918).
        This value occurs at the 4,997,555-th trapping square.
        A complete list of the first 5,000,000 trapping square values can be found here:
        <a href="/knight_trap_values/5million.txt" download>First 5,000,000 Trapping Squares</a>
      </p>
      <h5>Plots & Analysis</h5>
      <p class="bodytext">
        Plotting the value of the trapping squares against the order in which
        they are discovered yields the following plot:
      </p>
      <figure class="middlewide">
        <img src="/images-videos/Knight_Trap/Trapping_Squares_Graph.png" width="100%" height="470"
        alt="Trapping Squares Graph">
        <figcaption>Graph of Trapping Values vs Order of Discovery</figcaption>
      </figure>
      <p class="bodytext">
        Interestingly, the values of the trapping squares seem to increase linearly
        as the knight explores farther from the center. Though a linear relationship
        is not all that surprising, it is by no means a given! The size of the spirals
        increases as the square of the radius, by virtue of the nature of the puzzle, and
        there isn't any clear, logical intuition suggesting that the relationship would
        be linear, so the fact that it is linear is very interesting! (I actually
        would have guessed that it'd be logarithmic.) Another interesting observation
        is that the trapping squares remain relatively dense even at very large values.
        If this pattern does, in fact, continue indefinitely, then one would expect this
        series of values to be an <b>infinite</b> series. Although it's rather predicable
        that the number of trapping squares is (probably) infinite, it wasn't necessarily
        guaranteed. It's technically possible that there is a finite number of trapping
        squares, but I find it incredibly unlikely, especially given the data above. Perhaps
        a mathematician with expertise in proofs and map theory could prove my conjecture
        that the series is infinite, but I'm afraid that's a bit above my pay grade!
      </p>
      <p class="bodytext">
        Another interesting question to ask about this puzzle is this: As the knight
        explores to farther and farther trapping squares, does the distance
        between consecutive squares increase? I don't mean the difference between their
        values since, as the spirals get larger, even adjacent squares can have
        values differing by millions. What I'm refering to is the number of moves
        required for the knight to get from one trapping square to the next. By
        keeping track of the number of moves made by the knight between trapping
        squares for the first 20,000 values, I produced the following graph, which
        is the distance that the knight had to move to get to each square from
        the previous one:
      </p>
      <figure class="middlewide">
        <img src="/images-videos/Knight_Trap/Moves_Between_Squares.png" width="100%" height="470"
        alt="Moves between trapping squares">
        <figcaption>Number of Moves Between Consecutive Trapping Squares vs Square Order</figcaption>
      </figure>
      <p class="bodytext">
        This graph is ridiculously interesting. It reveals a number of <b>really</b>
        interesting truths. First, the number of moves required to reach each trapping
        square from the previous one does not significantly increase at extremely large
        values. The trend appears to be, at most, logarithmic, but could, in fact,
        be shown to be asymptotal with a large enough data set. This suggests that trapping squares
        are nearly as common at extreme distances as they are near the center. It also supports the conjecture that
        there are infinitely many trapping squares, since their frequency doesn't significantly
        decrease with distance from the center. Second, the number of moves
        between consecutive trapping squares has an undeniable 'banded' pattern. This is
        <b>so cool</b> because it is entirely unexpected. It seems that there are certain positions
        around the spiral that are more likely to result in a trap than others. I can't
        conceive of a logical explanation for why the distances between consecutive
        squares forms these 'dense bands' around 0, 3000, 6000, etc. (once the graph
        levels off) and similarly forms 'dead bands' in between them. Why does this off-and-on pattern exist? What
        is it about distances of 3,000 moves that makes them so much more common than
        distances of 1,500 or 5,000 moves? Further research into this phenomenon
        would be extremely interesting and could reveal greater truths about this
        puzzle.
      </p>
    </div>

<!---------------------------------------------------------------------------->
<!--                          Knight Tour                                    ->
<!---------------------------------------------------------------------------->

    <div class="main1">
      <h3 id="KnightTour">The Knight's Tour</h3>
      <h5>Background</h5>
      <p class="bodytext">
        The Knight's Tour is a famous, centuries-old chess puzzle which asks one question:
        How can a Knight (from the game of chess) navigate a chess board such that it visits every square
        exactly once? I love the game of chess so, naturally, when I learned about this
        puzzle, I became determined to solve it myself.
      </p>
      <h5>My Algorithm</h5>
      <figure class="rightmedium">
        <img src="/images-videos/Knight_Tour/Knight_Tour-8-0-0.gif" width="100%" height="315"
        alt="8x8 Knight's Tour">
        <figcaption>8x8 Knight's Tour</figcaption>
      </figure>
      <p class="bodytext">
        The problem seems, on the surface, incredibly daunting. My first strategy was to
        use a Mimimum Priority Queue, assigning a 'score' to every board based on the position
        of the knight and the locations of remaining squares. (This is the technique I used
        to solve Sliding Puzzles, and it is described in greater detail in that section.) However, this solution
        only succeeded in finding valid knight's tours for boards 5x5 and smaller; anything
        larger would exceed the computer's memory capacity or take too long. This is
        because such a strategy requires that the program store all possible previous boards for
        later retrieval, something that isn't feasible once the paths get very long.
      </p>
      <p class="bodytext">
        I realized that, to solve the problem for larger boards, I needed to develop a heuristic
        that would inform the decision of the knight at each move, but not require it to
        consider all possible paths. Choosing this heuristic was incredibly important, as it
        would determine the success of the program. After quite a bit of trial and error,
        I settled on the final, and ultimately successful, heuristic: When choosing the next square
        for the knight, choose the square which will give the knight the fewest available
        moves. Logically, this heuristic makes sense: it's in the knight's interest to keep
        its path compact and fill holes in otherwise visited space. This strategy minimizes
        the creation of 'islands' (unvisited squares to which there are no valid routes)
        because a square that is becoming isolated from other unvisited squares will be filled
        according to the heuristic.
      </p>
      <figure class="videomedium">
        <video width="350" height="350" controls autoplay>
          <source src="/images-videos/Knight_Tour/Knight_Tour-15-10-12.mp4"
          type="video/mp4">
          Your browser does not support this video.
        </video>
        <figcaption>15x15 Knight's Tour</figcaption>
      </figure>
      <p class="bodytext">
        Compared to my first attempt, the fewest-squares heuristic is superior by orders
        of magnitude. It minimizes the required memory and solves the puzzle in linear time.
        Additionally, by my calculations, the fewest-squares heuristic is successful
        in finding a knight's tour over <b>95%</b> of the time for all boards smaller than <b>80 x 80</b>
        with the knight in <b>any</b> position. Once the size of the boards reaches the hundreds, the success
        rate drops to around 50% and continues to fall as the sizes increase. A successful
        tour on a board of size 150x150 is shown (below).
      </p>
      <iframe style="height:400px;width:60%;position:relative;display:block;margin-left:auto;margin-right:auto"
        src="https://www.youtube.com/embed/yUQc2w1KGE0"
        title="YouTube video player" frameborder="0" allow="accelerometer; autoplay;
        clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
    </iframe>
    </div>

<!---------------------------------------------------------------------------->
<!--                          Sliding Puzzle                                 ->
<!---------------------------------------------------------------------------->

    <div class="main2">
      <h3 id="8Puzzle">The Sliding Puzzle Solver</h3>
      <p class="bodytext">
        I built this project as part of the course COS 226, <i>Algorithms and Data
        Structures</i>, at Princeton University.
      </p>
      <h5>Background</h5>
      <figure class="rightmedium">
        <img src="/images-videos/Sliding_Puzzle/Sliding_Puzzle_34.gif" width="100%" height="315"
        alt="4x4 Sliding Puzzle">
        <figcaption>4x4 Sliding Puzzle</figcaption>
      </figure>
      <p class="bodytext">
        The Sliding Puzzle is one of the most popular handheld puzzles
        in circulation. The task is simple: You are given a grid of squares, all
        filled in with the exception of one empty slot. These squares can slide past one
        another, and it is your job to put them in order from left to right and top
        to bottom, using only the one empty slot to move the squares around. Given enough
        time and moves, most people can solve a sliding puzzle, though they may struggle
        with larger ones. Nevertheless, my algorithm is designed to find the solution
        to any puzzle up to 5x5 in size in the shortest possible number of moves.
        <br>
      </p>
      <h5>My Algorithm</h5>
      <figure class="leftlarge">
        <img src="/images-videos/Sliding_Puzzle/PuzzleA.gif" width="100%" height="415"
        alt="5x5 Sliding Puzzle">
        <figcaption>5x5 Sliding Puzzle</figcaption>
      </figure>
      <p class="bodytext">
        In order to find the solution to slider puzzles, I used the
        <a href="https://en.wikipedia.org/wiki/A*_search_algorithm">A* Search Algorithm</a>
        with a Minimum Priority Queue. I defined a "search node" as a board, the number of moves
        made to reach it, and a reference to the previous node. Additionally, every board
        is assigned a "priority function," or a value that describes how worthwhile
        that board is to explore. The priority function I chose, known widely as the
        "Manhattan Priority Function," is given by the number of moves made to reach
        that board plus the "Manhattan Distance" of that board, where the Manhattan Distance is
        the sum of the vertical and horizontal distances from each tile to its
        solved location. This priority function gives lower values to boards which were
        reached in fewer moves and boards that are closer to the solution. Additionally, the Manhattan
        function of any board is always greater than or equal to the shortest possible number
        of steps needed to solve it from start to finish.
      </p>
      <p class="bodytext">
        As given by the A* Search Algorithm, the board with the lowest priority value is removed
        from the queue, the priority functions of all of its "children" (boards that can be
        reached in one move) are calculated, and the children are added back into to the queue.
        Once a board is removed from the queue which is equal to the final solution,
        you are guaranteed that you have found the shortest possible solution. This is because
        of the nature of the Manhattan Priority Function. At the moment it is removed from
        the queue, the solved board has the smallest priority function of all
        existing boards. Because all Manhattan Functions are greater than or equal to
        the solving distance, and because all <b>remaining</b> Manhattan Functions are larger
        than the solution just discovered, the found solution must be the quickest one.
      </p>
      <p class="bodytext">
        The largest board that my algorithm can solve (in a reasonable amount of time) is a
        5x5 board requiring 48 total moves to solve (below).
        <br><br>
      </p>
      <figure class="middlelarge">
        <img src="/images-videos/Sliding_Puzzle/PuzzleB.gif" width="100%" height="500"
        alt="5x5 Sliding Puzzle">
        <figcaption>5x5 Sliding Puzzle</figcaption>
      </figure>
    </div>

<!---------------------------------------------------------------------------->
<!--                          Recursive Artwork                              ->
<!---------------------------------------------------------------------------->

    <div class="main1">
      <h3 id="Recursive">Recursive Artwork</h3>
      <p class="bodytext">
        I built this project as part of the course COS 126, <i>Computer Science: An
        Interdisciplinary Approach</i>, at Princeton University.
      </p>
      <h5>Background</h5>
      <figure class="rightsmall">
        <img src="/images-videos/Recursion/Sierpinski.png" width="100%" height="215"
        alt="Sierpinski's Triangle">
        <figcaption>Sierpinski's Triangle</figcaption>
      </figure>
      <p class="bodytext">
        This project was an experiment in using computation and geometry to create
        fractals digitally. The inspiration for all of the fractal artwork contained
        herein was the Sierpinski Triangle (right). This famous fractal, named after
        mathematician and number theorist Waclaw Sierpinski, consists of one large
        equilateral triangle containing three smaller equilateral triangles, each containing
        three triangles of their own, and so on. This 'multiplicative' property of Sierpinski's
        Triangle is what makes recursive functions such a useful tool for creating art
        similar to Sierpinski's.
      </p>
      <h5>My Implementation</h5>
      <p class="bodytext">
        To create fractal artwork inspired by Sierpinski's Triangle, I used recursive
        functions in Java in conjuction with Princeton standard libraries (for drawing).
        The general structure of the algorithm is this: call a function that draws
        a particular shape or icon. However, before that function returns, have it
        recursively call <i>itself</i> multiple times with new position and size parameters
        for the drawing. Repeat this layered recursion 5-8 times (any more and the program
        starts to time out), each time drawing a smaller and smaller version of the
        same shape or icon in positions relative to their 'parent.' Depending on the
        choice of the initial shape and subsequent positioning of recursive children,
        a wide variety of fractals can form. Some of the more interesting and/or
        beautiful pieces that I created are shown below:
      </p>
      <div class="row">
        <figure class="sidebyside3">
          <img src="/images-videos/Recursion/Recursion_Random_Spiral1.png" alt="Raindow Spiral 1" style="width:100%;height:100%">
        </figure>
        <figure class="sidebyside3">
          <img src="/images-videos/Recursion/Recursion_Octagon.PNG" alt="Recursive Octagon" style="width:100%;height:100%">
        </figure>
        <figure class="sidebyside3">
          <img src="/images-videos/Recursion/Recursion_Random_Spiral2.PNG" alt="Raindow Spiral 2" style="width:100%;height:100%">
        </figure>
      </div>
      <div class="row">
        <figure class="sidebyside3">
          <img src="/images-videos/Recursion/Recursion_Ghost.PNG" alt="Ghost Tree" style="width:100%;height:100%">
        </figure>
        <figure class="sidebyside3">
          <video width=100% controls autoplay>
            <source src="/images-videos/Recursion/Recursion_Ghost.mp4"
            type="video/mp4">
            Your browser does not support this video.
          </video>
        </figure>
        <figure class="sidebyside3">
          <img src="/images-videos/Recursion/Recursion_Nested_Octagon.PNG" alt="Nested Octagon" style="width:100%;height:100%">
        </figure>
      </div>
    </div>

<!---------------------------------------------------------------------------->
<!--                          N-Body                                         ->
<!---------------------------------------------------------------------------->

    <div class="main2">
      <h3 id="NBody">The N-Body Problem</h3>
      <figure class="rightsmall">
        <img src="/images-videos/NBody/NBody_Simple.gif" width="100%" height="215"
        alt="Simple 4 Planet System">
        <figcaption>Simple 4 Planet System</figcaption>
      </figure>
      <p class="bodytext">
        I built this project as part of the course COS 126, <i>Computer Science: An
        Interdisciplinary Approach</i>, at Princeton University.
      </p>
      <h5>Background</h5>
      <p class="bodytext">
        The N-Body Problem is the problem of predicting the motion of N astronomical
        bodies subject to the forces of gravity between them. Solving this problem is
        not particularly difficult for small systems with only a few bodies. An example
        of such a simple system is shown (right), where only 5 bodies exist in perfectly
        circular orbits. However, the problem becomes incredibly complicated to calculate once large numbers of bodies
        are involved. For this project, rather than algebraically solve for the equations of motion for
        an arbitrarily large system, I sought to solve the N-Body problem computationally, instead.
      </p>
      <h5>My Implementation</h5>
      <p class="bodytext">
        To do this, I treated the passage of time as a series of very short time steps and calculated
        the changes in trajectories at each step. Given the initial positions, velocities, and masses
        of any number of bodies, my algorithm uses Newton's Law of Universal Gravitation,
        <img src="/images-videos/NBody/Gravity_Equation.jpg" alt="Newton's Law of Universal Gravity"
        width="80px" height="35px" style="display:inline; justify-content: center;">,
        to calculate the force on each body due to all others, the subsequent
        acceleration due to that force, and the change in velocity over a
        short time step due to that acceleration. This new velocity is used to determine
        the new position of each body. This process repeats for each small time step,
        and the results are animated to illustrate the motion of the bodies over time.
        The results of these long simulations, given the right initial conditions,
        can be incredible beautiful and interesting. A few of the most interesting
        simulations are shown (below).
      </p>
      <div class="row">
        <figure class="sidebyside2">
          <img src="/images-videos/NBody/NBody_Binary.gif" style="width:100%;height:100%"
          alt="Binary Star System">
        </figure>
        <figure class="sidebyside2">
          <img src="/images-videos/NBody/NBody_Figure8.gif" style="width:100%;height:100%"
          alt="Figure 8 System">
        </figure>
      </div>
      <div class="row">
        <figure class="sidebyside2">
          <video width=100% controls autoplay muted>
            <source src="/images-videos/NBody/NBody_Spiral.mp4"
            type="video/mp4">
            Your browser does not support this video.
          </video>
        </figure>
        <figure class="sidebyside2">
          <video width=100% controls autoplay muted>
            <source src="/images-videos/NBody/NBody_ChaosBlossom.mp4"
            type="video/mp4">
            Your browser does not support this video.
          </video>
        </figure>
      </div>
    </div>

<!---------------------------------------------------------------------------->
<!--                          Bouncing Balls                                 ->
<!---------------------------------------------------------------------------->

    <div class="main1">
      <h3 id="Balls">Bouncing Balls</h3>
      <h5>Background</h5>
      <figure class="rightsmall">
        <img src="/images-videos/Bouncing_Balls/dvd_logo.gif" width="100%" height="215"
        alt="Bouncing DVD Logo">
        <figcaption>The Classic DVD Logo</figcaption>
      </figure>
      <p class="bodytext">
        The bouncing balls is a fun program that simulates N balls bouncing in
        a closed 2-dimensional room subject to the force of gravity and collisions
        with eachother and the walls. My process for creating this program went in
        several stages, each progressing from the previous.
      </p>
      <h5>Inspiration</h5>
      <p class="bodytext">
        When I started, I wasn't actually planning to animate bouncing balls at all. Earlier
        that day, I had been staring at the classic bouncing DVD logo (right) on my family
        TV and was infuriated that the square never landed perfectly in the center. Driven mad by
        ill-conceived rage, I decided that I would create <b>my own</b> DVD logo that
        would hit the corner <b>every single time</b> so that I could witness that
        ever-satisfying perfect corner hit. (but also to spite the universe...) However,
        with a little trigonometry, this problem turned out to be <i>very</i> easy. At that
        point, I figured, "I built this, so I might as well use it for something interesting."
        Thus, I added gravity so that the motion of the square would be a bit more
        dynamic. I also replaced the square with a tennis ball because, let's face it,
        everything is better when sports are involved!
      </p>
      <h5>Next Steps</h5>
      <figure class="rightmedium">
        <img src="/images-videos/Bouncing_Balls/Bouncing_Balls-7.gif" width="100%" height="315"
        alt="7 Bouncing Balls">
        <figcaption>7 Bouncing Balls</figcaption>
      </figure>
      <p class="bodytext">
        From there, I decided to add a few more balls. I just had to convert my
        position and velocity variables into arrays so that I could store data on
        multiple balls at once. Pretty soon, I had 5 balls bouncing around my screen!
        From there, I added a command-line input that would take an integer as the
        number of balls and animate the requested number. Along with that change, I created a function
        to scale-down the size of the balls as their numbers increased to prevent
        them from crowding the screen with a giant mass of yellow-green. I also added a small
        damping force to all wall collisions so that the balls would lose a bit of energy
        with each bounce in an effort to make the simulation slightly more realistic. Because of
        this damping force, the balls would eventually stop bouncing and just roll on the
        ground, so I added a ball-return function to start them back up bouncing after
        they'd run out of energy.
      </p>
      <h5>My Final Implementation</h5>
      <p class="bodytext">
        Unfortunately, the balls would just phase through each other instead of colliding,
        and being the perfectionist that I am, I could not tolerate this. Thus, I adjusted
        my code to account for mid-air collisions. This was more challenging
        than the previous iterations, but it's this addition that makes my animation
        so fun to watch. I had to check every ball's radial distance to all of its
        neighbors and determine, based on their velocities relative to eachother, whether
        or not they were colliding in that particular time step. If so, I had to
        calculate the outcome velocities of an elastic collision between the balls
        to determine the resulting trajectories. This addition reduced the
        time-efficiency of my program from linear time to quadratic time, but this
        change did not affect the performance of my animation because the number of balls
        remained relatively small compared to the computing power of my device. With
        this final addition, I set my program running and enjoyed the final product.
      </p>
      <figure class="videolarge">
        <video width="500" height="500" controls autoplay>
          <source src="/images-videos/Bouncing_Balls/200_Bouncing_Balls.mp4"
          type="video/mp4">
          Your browser does not support this video.
        </video>
        <figcaption>200 Bouncing Balls</figcaption>
      </figure>
    </div>

    <p class="bottomtext">
      <br><br><br>
      ___________________________________________________________
      <br><br>
      Created and coded in entirety by Jeb Carter
      <br>
      Copyright &copy; 2020-2024 Jeb Carter. All rights reserved.
      <br>
      ___________________________________________________________
    </p>

  </body>
</html>
